# -*- coding: utf-8 -*-
"""MS collect his data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M_E3emls8V70RvxxJael82g8x3xmEWzd
"""

!rm -rf /content/drive
!mkdir /content/drive

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import requests
import pandas as pd
from datetime import datetime

# Google Drive 路徑設定
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'

# 初始數據抓取函數：從指定開始時間抓取每小時的歷史數據
def fetch_data_from_start(start_date="2020-04-09 03:00:00", total_hours=40000, batch_hours=2000):
    all_data = []
    from_timestamp = int(datetime.strptime(start_date, "%Y-%m-%d %H:%M:%S").timestamp())

    while total_hours > 0:
        url = 'https://min-api.cryptocompare.com/data/v2/histohour'
        params = {
            'fsym': 'BTC',
            'tsym': 'USD',
            'limit': min(batch_hours - 1, total_hours - 1),
            'toTs': from_timestamp + 3600 * min(batch_hours, total_hours)
        }

        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()['Data']['Data']
            all_data.extend(data)
            from_timestamp = data[-1]['time']
            total_hours -= batch_hours
        else:
            print(f"Error: {response.status_code}")
            break

    df = pd.DataFrame(all_data)
    df['timestamp'] = pd.to_datetime(df['time'], unit='s')
    df.set_index('timestamp', inplace=True)
    return df[['open', 'high', 'low', 'close', 'volumefrom', 'volumeto']]

# 檢查 CSV 文件是否已經存在並從上次時間點延續抓取
if os.path.exists(csv_file_path):
    print("Existing data found. Loading previous data...")
    df_existing = pd.read_csv(csv_file_path, index_col='timestamp', parse_dates=True)
    last_timestamp = int(df_existing.index[-1].timestamp())
    print(f"Last timestamp in existing data: {df_existing.index[-1]}")
    df_new = fetch_data_from_start(total_hours=2000)  # 抓取最新數據
    df_combined = pd.concat([df_existing, df_new]).drop_duplicates()
else:
    print("No previous data found. Starting from specified start date.")
    df_combined = fetch_data_from_start()

# 保存更新的數據到 CSV
df_combined.to_csv(csv_file_path)
print("Data fetched and saved successfully.")

import os

csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'

if os.path.exists(csv_file_path):
    print("File found.")
else:
    print("File not found. Please check the path.")

import pandas as pd

# 讀取 CSV 文件
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'
df = pd.read_csv(csv_file_path, index_col='timestamp', parse_dates=True)

# 檢查是否有缺失的日期時間索引
missing_timestamp = df.index.isna().sum()
print(f"缺失的 timestamp 數量: {missing_timestamp}")

# 如果有缺失的 timestamp，找出這些行的位置
if missing_timestamp > 0:
    print("缺失 timestamp 的行：")
    print(df[df.index.isna()])
else:
    print("所有 timestamp 都有效。")

# 刪除缺失的 index 行（即含有 NaT 的 timestamp）
df = df[~df.index.isna()]

# 保存清理後的數據到 CSV 文件
df.to_csv(csv_file_path)

import os
import requests
import pandas as pd
from datetime import datetime

# 設定CSV文件路徑
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'

# 增量抓取函數：從指定的最後時間戳開始逐小時批量抓取
def fetch_continuous_data(start_timestamp, fsym="BTC", tsym="USD", batch_size=200):
    all_data = []
    current_timestamp = int(datetime.utcnow().timestamp())  # 當前 UTC 時間戳
    start_timestamp += 3600  # 移到下一個小時

    # 批量抓取直到接近當前時間
    while start_timestamp < current_timestamp:
        url = 'https://min-api.cryptocompare.com/data/v2/histohour'
        params = {
            'fsym': fsym,
            'tsym': tsym,
            'limit': batch_size - 1,
            'toTs': min(start_timestamp + 3600 * batch_size, current_timestamp)
        }

        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()['Data']['Data']
            if data:
                new_timestamp = data[-1]['time']
                if new_timestamp == start_timestamp:
                    print("No further data progression; ending fetch to avoid loop.")
                    break
                all_data.extend(data)
                start_timestamp = new_timestamp  # 更新至最新抓取的時間戳
                print(f"Fetched data up to: {datetime.utcfromtimestamp(start_timestamp)}")  # 確認抓取進度
            else:
                print("No more data available from API.")
                break
        else:
            print(f"Error fetching data: {response.status_code}")
            break

    # 建立 DataFrame 並設置索引
    df_new = pd.DataFrame(all_data)
    if not df_new.empty:
        df_new['timestamp'] = pd.to_datetime(df_new['time'], unit='s')
        df_new.set_index('timestamp', inplace=True)
        return df_new[['open', 'high', 'low', 'close', 'volumefrom', 'volumeto']]
    else:
        return pd.DataFrame()  # 返回空 DataFrame 以防無數據

# 檢查 CSV 文件是否存在並獲取最後時間戳
if os.path.exists(csv_file_path):
    df_existing = pd.read_csv(csv_file_path, index_col='timestamp', parse_dates=True)
    last_timestamp = int(df_existing.index[-1].timestamp())
    print(f"Existing data found. Last timestamp: {df_existing.index[-1]}")
else:
    print("No previous data found. Please ensure there is a valid start date.")
    df_existing = pd.DataFrame()
    last_timestamp = int(datetime(2024, 10, 31, 19, 0, 0).timestamp())  # 指定的開始時間

# 抓取新數據
df_new = fetch_continuous_data(start_timestamp=last_timestamp)

if not df_new.empty:
    # 過濾新數據中的重複 timestamp，僅保留在 df_existing 中不存在的 timestamp
    if not df_existing.empty:
        df_new_filtered = df_new[~df_new.index.isin(df_existing.index)]
    else:
        df_new_filtered = df_new  # 如果 df_existing 為空，保留所有新數據

    if not df_new_filtered.empty:
        # 合併數據，保留原有的 timestamp 資料
        df_combined = pd.concat([df_existing, df_new_filtered]).sort_index()

        # 去重，保留第一個出現的值
        df_combined = df_combined[~df_combined.index.duplicated(keep='first')]

        # 存入CSV文件
        df_combined.to_csv(csv_file_path)
        print("Data fetched and saved successfully.")
    else:
        print("No new unique timestamps found to save.")
else:
    print("No new data fetched.")

# 刪除最後 6 筆資料
df = df.iloc[:-17]

# 保存刪除後的數據到 CSV 文件
df.to_csv(csv_file_path)

print("已成功刪除最後 17 筆資料並保存到 CSV。")

import pandas as pd

# 設置 CSV 文件路徑
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'

# 讀取 CSV 文件
df = pd.read_csv(csv_file_path, index_col='timestamp', parse_dates=True)

# 設定日期範圍
start_date = "2024-09-30"
end_date = "2025-03-02"

# 過濾指定範圍內的數據
df = df.loc[start_date:end_date]

# 依照每週計算最高價與最低價
weekly_df = df.resample('W').agg({'high': 'max', 'low': 'min'}).reset_index()
weekly_df.rename(columns={'high': 'Highest High', 'low': 'Lowest Low'}, inplace=True)
weekly_df['Week'] = weekly_df['timestamp'].dt.strftime("%Y-%m-%d")

# 直接打印表格
print(weekly_df[['Week', 'Highest High', 'Lowest Low']])