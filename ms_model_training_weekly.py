# -*- coding: utf-8 -*-
"""MS model training_weekly.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17JNTgo-mDkIipKjZ0NI2fzL3k0RPsR02
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.makedirs('/content/drive/My Drive/master project', exist_ok=True)

!pip install pandas_ta

import os

csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_prediction_weekly.csv'

if os.path.exists(csv_file_path):
    print("File found.")
else:
    print("File not found. Please check the path.")

import os
import pandas as pd
import numpy as np
from datetime import timedelta
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping
import pandas_ta as ta

# 设置 CSV 文件路径
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_prediction_weekly.csv'

# 读取 CSV 文件
df = pd.read_csv(csv_file_path, usecols=['timestamp', 'open', 'high', 'low', 'close', 'volumefrom', 'volumeto'], index_col='timestamp', parse_dates=True)

# ----------------- Fibonacci Retracement -----------------
def fibonacci_retracement_weekly(data):
    weekly_data = data.resample('W').agg({'high': 'max', 'low': 'min'})
    high_price = weekly_data['high']
    low_price = weekly_data['low']
    diff = high_price - low_price

    weekly_data['fib_0.236'] = high_price - diff * 0.236
    weekly_data['fib_0.382'] = high_price - diff * 0.382
    weekly_data['fib_0.5'] = high_price - diff * 0.5
    weekly_data['fib_0.618'] = high_price - diff * 0.618
    weekly_data['fib_0.786'] = high_price - diff * 0.786

    weekly_data = weekly_data.reset_index()
    data = data.reset_index()

    data = pd.merge_asof(data.sort_values('timestamp'),
                         weekly_data.sort_values('timestamp'),
                         on='timestamp', direction='forward')

    data = data.rename(columns={'high_x': 'high', 'low_x': 'low'})
    data.drop(columns=['high_y', 'low_y'], inplace=True, errors='ignore')

    data.set_index('timestamp', inplace=True)
    return data

df = fibonacci_retracement_weekly(df)

# 移除重复的索引标签
df = df[~df.index.duplicated(keep='first')]

# ----------------- 计算技术指标 -----------------
df['SMA'] = ta.sma(df['close'], length=30)
df['EMA'] = ta.ema(df['close'], length=30)
bbands = ta.bbands(df['close'], length=20)
df['upper_band'] = bbands['BBU_20_2.0']
df['middle_band'] = bbands['BBM_20_2.0']
df['lower_band'] = bbands['BBL_20_2.0']
macd = ta.macd(df['close'], fast=12, slow=26, signal=9)
df['MACD'] = macd['MACD_12_26_9']
df['MACD_signal'] = macd['MACDs_12_26_9']

# ----------------- 计算 K棒（蠟燭圖）特征 -----------------
df['candle_body'] = abs(df['close'] - df['open'])
df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)
df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']

# ----------------- 处理 NaN 和 Inf 值 -----------------
df.fillna(method='ffill', inplace=True)
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(inplace=True)

# ----------------- 数据标准化 -----------------
features = ['SMA', 'EMA', 'upper_band', 'middle_band', 'lower_band',
            'MACD', 'MACD_signal', 'fib_0.236', 'fib_0.382', 'fib_0.5', 'fib_0.618', 'fib_0.786',
            'candle_body', 'upper_shadow', 'lower_shadow']

scaler_X = MinMaxScaler(feature_range=(0, 1))
X_scaled = scaler_X.fit_transform(df[features])

scaler_y = MinMaxScaler(feature_range=(0, 1))
y_scaled = scaler_y.fit_transform(df['close'].values.reshape(-1, 1))

# ----------------- 创建序列数据 -----------------
time_steps = 5
def create_sequences(X, y, time_steps):
    Xs, ys = [], []
    for i in range(time_steps, len(X)):
        Xs.append(X[i - time_steps:i])
        ys.append(y[i])
    return np.array(Xs), np.array(ys)

X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)

# ----------------- 划分训练集、验证集和测试集 -----------------
X_train_full, X_test, y_train_full, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)

# ----------------- 构建 LSTM 模型 -----------------
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# 编译模型
model.compile(optimizer='rmsprop', loss='mean_squared_error')

# 训练模型
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))

# ----------------- 预测下一周 -----------------
from datetime import timedelta

start_date = "2025-02-17 00:00:00"
end_date = "2025-02-23 23:00:00"

weekly_data = df.loc[start_date:end_date, features]

if len(weekly_data) == 168:
    weekly_data_scaled = scaler_X.transform(weekly_data)
    weekly_data_scaled = weekly_data_scaled.reshape((1, weekly_data_scaled.shape[0], weekly_data_scaled.shape[1]))

    predicted_close_scaled = model.predict(weekly_data_scaled)
    predicted_close = scaler_y.inverse_transform(predicted_close_scaled)[0][0]

    prediction_date = pd.to_datetime(end_date) + timedelta(days=1)
    prediction_date = prediction_date.replace(hour=0, minute=0, second=0, microsecond=0)

    df.loc[prediction_date, 'predict(週)'] = predicted_close
    df.to_csv(csv_file_path)

    print(f"Prediction for {prediction_date} (週): {predicted_close}")
else:
    print("The specified week's data is incomplete or missing.")

full_range = pd.date_range(start="2025-02-17", end="2025-02-23 23:00:00", freq="H")
missing_timestamps = full_range.difference(df.index)

if not missing_timestamps.empty:
    print("Missing timestamps:")
    print(missing_timestamps)
else:
    print("No missing timestamps.")

import pandas as pd

# 設置 CSV 文件路徑
csv_file_path = '/content/drive/My Drive/master project/bitcoin_data_and_predictions.csv'

# 讀取 CSV 文件
df = pd.read_csv(csv_file_path, index_col='timestamp', parse_dates=True)

# 指定日期範圍
start_date = "2024-11-25"
end_date = "2024-12-01"

# 過濾出指定時間段的數據
filtered_data = df.loc[start_date:end_date]

# 計算 high 的最高值和 low 的最低值
highest_high = filtered_data['high'].max()
lowest_low = filtered_data['low'].min()

# 輸出結果
print(f"From {start_date} to {end_date}:")
print(f"Highest 'high' value: {highest_high}")
print(f"Lowest 'low' value: {lowest_low}")